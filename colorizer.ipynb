{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":68107,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":56782}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport cv2\nfrom tensorflow.keras.optimizers import Adam\n!pip install mlflow dagshub\nimport mlflow\nimport mlflow.tensorflow as mltf\n","metadata":{"execution":{"iopub.status.busy":"2024-06-25T06:42:25.981909Z","iopub.execute_input":"2024-06-25T06:42:25.982622Z","iopub.status.idle":"2024-06-25T06:42:39.211975Z","shell.execute_reply.started":"2024-06-25T06:42:25.982588Z","shell.execute_reply":"2024-06-25T06:42:39.210759Z"},"trusted":true},"execution_count":60,"outputs":[{"name":"stdout","text":"Requirement already satisfied: mlflow in /opt/conda/lib/python3.10/site-packages (2.14.1)\nRequirement already satisfied: dagshub in /opt/conda/lib/python3.10/site-packages (0.3.28)\nRequirement already satisfied: Flask<4 in /opt/conda/lib/python3.10/site-packages (from mlflow) (3.0.3)\nRequirement already satisfied: alembic!=1.10.0,<2 in /opt/conda/lib/python3.10/site-packages (from mlflow) (1.13.1)\nRequirement already satisfied: cachetools<6,>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from mlflow) (5.3.2)\nRequirement already satisfied: click<9,>=7.0 in /opt/conda/lib/python3.10/site-packages (from mlflow) (8.1.7)\nRequirement already satisfied: cloudpickle<4 in /opt/conda/lib/python3.10/site-packages (from mlflow) (2.2.1)\nRequirement already satisfied: docker<8,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from mlflow) (7.0.0)\nRequirement already satisfied: entrypoints<1 in /opt/conda/lib/python3.10/site-packages (from mlflow) (0.4)\nRequirement already satisfied: gitpython<4,>=3.1.9 in /opt/conda/lib/python3.10/site-packages (from mlflow) (3.1.41)\nRequirement already satisfied: graphene<4 in /opt/conda/lib/python3.10/site-packages (from mlflow) (3.3)\nRequirement already satisfied: importlib-metadata!=4.7.0,<8,>=3.7.0 in /opt/conda/lib/python3.10/site-packages (from mlflow) (6.11.0)\nRequirement already satisfied: markdown<4,>=3.3 in /opt/conda/lib/python3.10/site-packages (from mlflow) (3.5.2)\nRequirement already satisfied: matplotlib<4 in /opt/conda/lib/python3.10/site-packages (from mlflow) (3.7.5)\nRequirement already satisfied: numpy<2 in /opt/conda/lib/python3.10/site-packages (from mlflow) (1.26.4)\nRequirement already satisfied: opentelemetry-api<3,>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from mlflow) (1.22.0)\nRequirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from mlflow) (1.22.0)\nRequirement already satisfied: packaging<25 in /opt/conda/lib/python3.10/site-packages (from mlflow) (21.3)\nRequirement already satisfied: pandas<3 in /opt/conda/lib/python3.10/site-packages (from mlflow) (2.2.1)\nRequirement already satisfied: protobuf<5,>=3.12.0 in /opt/conda/lib/python3.10/site-packages (from mlflow) (3.20.3)\nRequirement already satisfied: pyarrow<16,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from mlflow) (14.0.2)\nRequirement already satisfied: pytz<2025 in /opt/conda/lib/python3.10/site-packages (from mlflow) (2023.3.post1)\nRequirement already satisfied: pyyaml<7,>=5.1 in /opt/conda/lib/python3.10/site-packages (from mlflow) (6.0.1)\nRequirement already satisfied: querystring-parser<2 in /opt/conda/lib/python3.10/site-packages (from mlflow) (1.2.4)\nRequirement already satisfied: requests<3,>=2.17.3 in /opt/conda/lib/python3.10/site-packages (from mlflow) (2.32.3)\nRequirement already satisfied: scikit-learn<2 in /opt/conda/lib/python3.10/site-packages (from mlflow) (1.2.2)\nRequirement already satisfied: scipy<2 in /opt/conda/lib/python3.10/site-packages (from mlflow) (1.11.4)\nRequirement already satisfied: sqlalchemy<3,>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from mlflow) (2.0.25)\nRequirement already satisfied: sqlparse<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from mlflow) (0.4.4)\nRequirement already satisfied: Jinja2<4,>=2.11 in /opt/conda/lib/python3.10/site-packages (from mlflow) (3.1.2)\nRequirement already satisfied: gunicorn<23 in /opt/conda/lib/python3.10/site-packages (from mlflow) (22.0.0)\nRequirement already satisfied: fusepy>=3 in /opt/conda/lib/python3.10/site-packages (from dagshub) (3.0.1)\nRequirement already satisfied: appdirs>=1.4.4 in /opt/conda/lib/python3.10/site-packages (from dagshub) (1.4.4)\nRequirement already satisfied: httpx~=0.23.0 in /opt/conda/lib/python3.10/site-packages (from dagshub) (0.23.3)\nRequirement already satisfied: rich~=13.1.0 in /opt/conda/lib/python3.10/site-packages (from dagshub) (13.1.0)\nRequirement already satisfied: dacite~=1.6.0 in /opt/conda/lib/python3.10/site-packages (from dagshub) (1.6.0)\nRequirement already satisfied: tenacity~=8.2.2 in /opt/conda/lib/python3.10/site-packages (from dagshub) (8.2.3)\nRequirement already satisfied: gql[requests] in /opt/conda/lib/python3.10/site-packages (from dagshub) (3.5.0)\nRequirement already satisfied: dataclasses-json in /opt/conda/lib/python3.10/site-packages (from dagshub) (0.6.6)\nRequirement already satisfied: treelib~=1.6.4 in /opt/conda/lib/python3.10/site-packages (from dagshub) (1.6.4)\nRequirement already satisfied: pathvalidate~=3.0.0 in /opt/conda/lib/python3.10/site-packages (from dagshub) (3.0.0)\nRequirement already satisfied: python-dateutil in /opt/conda/lib/python3.10/site-packages (from dagshub) (2.9.0.post0)\nRequirement already satisfied: boto3 in /opt/conda/lib/python3.10/site-packages (from dagshub) (1.26.100)\nRequirement already satisfied: Mako in /opt/conda/lib/python3.10/site-packages (from alembic!=1.10.0,<2->mlflow) (1.3.5)\nRequirement already satisfied: typing-extensions>=4 in /opt/conda/lib/python3.10/site-packages (from alembic!=1.10.0,<2->mlflow) (4.9.0)\nRequirement already satisfied: urllib3>=1.26.0 in /opt/conda/lib/python3.10/site-packages (from docker<8,>=4.0.0->mlflow) (1.26.18)\nRequirement already satisfied: Werkzeug>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from Flask<4->mlflow) (3.0.3)\nRequirement already satisfied: itsdangerous>=2.1.2 in /opt/conda/lib/python3.10/site-packages (from Flask<4->mlflow) (2.2.0)\nRequirement already satisfied: blinker>=1.6.2 in /opt/conda/lib/python3.10/site-packages (from Flask<4->mlflow) (1.8.2)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from gitpython<4,>=3.1.9->mlflow) (4.0.11)\nRequirement already satisfied: graphql-core<3.3,>=3.1 in /opt/conda/lib/python3.10/site-packages (from graphene<4->mlflow) (3.2.3)\nRequirement already satisfied: graphql-relay<3.3,>=3.1 in /opt/conda/lib/python3.10/site-packages (from graphene<4->mlflow) (3.2.0)\nRequirement already satisfied: aniso8601<10,>=8 in /opt/conda/lib/python3.10/site-packages (from graphene<4->mlflow) (9.0.1)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx~=0.23.0->dagshub) (2024.2.2)\nRequirement already satisfied: httpcore<0.17.0,>=0.15.0 in /opt/conda/lib/python3.10/site-packages (from httpx~=0.23.0->dagshub) (0.16.3)\nRequirement already satisfied: rfc3986<2,>=1.3 in /opt/conda/lib/python3.10/site-packages (from rfc3986[idna2008]<2,>=1.3->httpx~=0.23.0->dagshub) (1.5.0)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx~=0.23.0->dagshub) (1.3.0)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata!=4.7.0,<8,>=3.7.0->mlflow) (3.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from Jinja2<4,>=2.11->mlflow) (2.1.3)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4->mlflow) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4->mlflow) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4->mlflow) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4->mlflow) (1.4.5)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4->mlflow) (9.5.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4->mlflow) (3.1.1)\nRequirement already satisfied: deprecated>=1.2.6 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-api<3,>=1.9.0->mlflow) (1.2.14)\nRequirement already satisfied: opentelemetry-semantic-conventions==0.43b0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow) (0.43b0)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas<3->mlflow) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil->dagshub) (1.16.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.17.3->mlflow) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.17.3->mlflow) (3.6)\nRequirement already satisfied: commonmark<0.10.0,>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from rich~=13.1.0->dagshub) (0.9.1)\nRequirement already satisfied: pygments<3.0.0,>=2.6.0 in /opt/conda/lib/python3.10/site-packages (from rich~=13.1.0->dagshub) (2.17.2)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn<2->mlflow) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn<2->mlflow) (3.2.0)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.0.3)\nRequirement already satisfied: botocore<1.30.0,>=1.29.100 in /opt/conda/lib/python3.10/site-packages (from boto3->dagshub) (1.29.165)\nRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from boto3->dagshub) (1.0.1)\nRequirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from boto3->dagshub) (0.6.2)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json->dagshub) (3.21.2)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json->dagshub) (0.9.0)\nRequirement already satisfied: yarl<2.0,>=1.6 in /opt/conda/lib/python3.10/site-packages (from gql[requests]->dagshub) (1.9.3)\nRequirement already satisfied: backoff<3.0,>=1.11.1 in /opt/conda/lib/python3.10/site-packages (from gql[requests]->dagshub) (2.2.1)\nRequirement already satisfied: anyio<5,>=3.0 in /opt/conda/lib/python3.10/site-packages (from gql[requests]->dagshub) (4.2.0)\nRequirement already satisfied: requests-toolbelt<2,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from gql[requests]->dagshub) (1.0.0)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.0->gql[requests]->dagshub) (1.2.0)\nRequirement already satisfied: wrapt<2,>=1.10 in /opt/conda/lib/python3.10/site-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow) (1.14.1)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow) (5.0.1)\nRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore<0.17.0,>=0.15.0->httpx~=0.23.0->dagshub) (0.14.0)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->dagshub) (1.0.0)\nRequirement already satisfied: multidict>=4.0 in /opt/conda/lib/python3.10/site-packages (from yarl<2.0,>=1.6->gql[requests]->dagshub) (6.0.4)\n","output_type":"stream"}]},{"cell_type":"code","source":"from huggingface_hub import login\naccess_token_read = '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'\nlogin(token = access_token_read)","metadata":{"execution":{"iopub.status.busy":"2024-06-25T07:11:54.958144Z","iopub.execute_input":"2024-06-25T07:11:54.958892Z","iopub.status.idle":"2024-06-25T07:11:55.074788Z","shell.execute_reply.started":"2024-06-25T07:11:54.958859Z","shell.execute_reply":"2024-06-25T07:11:55.073932Z"},"trusted":true},"execution_count":83,"outputs":[{"name":"stdout","text":"The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\nToken is valid (permission: read).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}]},{"cell_type":"code","source":"import dagshub\n\ndagshub.init(\"pycolorizer\", \"realrohilbansal\", mlflow=True)","metadata":{"execution":{"iopub.status.busy":"2024-06-25T07:11:55.252237Z","iopub.execute_input":"2024-06-25T07:11:55.252513Z","iopub.status.idle":"2024-06-25T07:11:55.431965Z","shell.execute_reply.started":"2024-06-25T07:11:55.252489Z","shell.execute_reply":"2024-06-25T07:11:55.431139Z"},"trusted":true},"execution_count":84,"outputs":[{"output_type":"display_data","data":{"text/plain":"Initialized MLflow to track repo \u001b[32m\"realrohilbansal/pycolorizer\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"realrohilbansal/pycolorizer\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Repository realrohilbansal/pycolorizer initialized!\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository realrohilbansal/pycolorizer initialized!\n</pre>\n"},"metadata":{}}]},{"cell_type":"code","source":"experiment_name = \"pycolorizer\" \nartifact_location = \"pycolorizer_artifacts\"\nexperiment = mlflow.get_experiment_by_name(experiment_name)\nif experiment is None:\n    experiment_id = mlflow.create_experiment(experiment_name, artifact_location)\nelse:\n    experiment_id = experiment.experiment_id","metadata":{"execution":{"iopub.status.busy":"2024-06-25T07:11:57.347570Z","iopub.execute_input":"2024-06-25T07:11:57.348376Z","iopub.status.idle":"2024-06-25T07:11:57.534609Z","shell.execute_reply.started":"2024-06-25T07:11:57.348338Z","shell.execute_reply":"2024-06-25T07:11:57.533877Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"code","source":"mlflow.set_tracking_uri('https://dagshub.com/realrohilbansal/pycolorizer.mlflow')\n\nmlflow.set_experiment(experiment_name)","metadata":{"execution":{"iopub.status.busy":"2024-06-25T07:11:58.788123Z","iopub.execute_input":"2024-06-25T07:11:58.788580Z","iopub.status.idle":"2024-06-25T07:11:58.966763Z","shell.execute_reply.started":"2024-06-25T07:11:58.788547Z","shell.execute_reply":"2024-06-25T07:11:58.965921Z"},"trusted":true},"execution_count":86,"outputs":[{"execution_count":86,"output_type":"execute_result","data":{"text/plain":"<Experiment: artifact_location='/app/pycolorizer_artifacts', creation_time=1719298699628, experiment_id='0', last_update_time=1719298699628, lifecycle_stage='active', name='pycolorizer', tags={}>"},"metadata":{}}]},{"cell_type":"code","source":"def getexperiment(experiment_id: str=None, experiment_name:str=None):\n    if experiment_id is not None:\n        experiment = mlflow.get_experiment(experiment_id)\n    elif experiment_name is not None:\n        experiment = mlflow.get_experiment_by_name(experiment_name)\n    else:\n        raise ValueError(\"Either Experiment ID or Experiment Name must be provided.\")\n    \n    print(\"Name: \", experiment.name)\n    print(\"ID: \", experiment.experiment_id)\n    print(\"Artifact location: \", experiment.artifact_location)\n    # print(\"Tags: \", experiment.tags)\n    print(\"Creation timestamp: \", experiment.creation_time)\n    print(\"Lifecycle stage: \", experiment.lifecycle_stage)\n    \n    return experiment","metadata":{"execution":{"iopub.status.busy":"2024-06-25T07:12:02.909630Z","iopub.execute_input":"2024-06-25T07:12:02.910000Z","iopub.status.idle":"2024-06-25T07:12:02.916310Z","shell.execute_reply.started":"2024-06-25T07:12:02.909972Z","shell.execute_reply":"2024-06-25T07:12:02.915374Z"},"trusted":true},"execution_count":87,"outputs":[]},{"cell_type":"code","source":"def downsample(filters, size, apply_batchnorm=True):\n    initializer = tf.random_normal_initializer(0., 0.02)\n    result = tf.keras.Sequential()\n    result.add(layers.Conv2D(filters, size, strides=2, padding='same', kernel_initializer=initializer, use_bias=False))\n    if apply_batchnorm:\n        result.add(layers.BatchNormalization())\n    result.add(layers.LeakyReLU())\n    return result\n\ndef upsample(filters, size, apply_dropout=False):\n    initializer = tf.random_normal_initializer(0., 0.02)\n    result = tf.keras.Sequential()\n    result.add(layers.Conv2DTranspose(filters, size, strides=2, padding='same', kernel_initializer=initializer, use_bias=False))\n    result.add(layers.BatchNormalization())\n    if apply_dropout:\n        result.add(layers.Dropout(0.5))\n    result.add(layers.ReLU())\n    return result\n\ndef Generator():\n    inputs = tf.keras.layers.Input(shape=[256, 256, 1])\n    down_stack = [\n        downsample(64, 4, apply_batchnorm=False),\n        downsample(128, 4),\n        downsample(256, 4),\n        downsample(512, 4),\n        downsample(512, 4),\n        downsample(512, 4),\n        downsample(512, 4),\n        downsample(512, 4),\n    ]\n    up_stack = [\n        upsample(512, 4, apply_dropout=True),\n        upsample(512, 4, apply_dropout=True),\n        upsample(512, 4, apply_dropout=True),\n        upsample(512, 4),\n        upsample(256, 4),\n        upsample(128, 4),\n        upsample(64, 4),\n    ]\n    initializer = tf.random_normal_initializer(0., 0.02)\n    last = layers.Conv2DTranspose(3, 4, strides=2, padding='same', kernel_initializer=initializer, activation='tanh')\n    x = inputs\n    skips = []\n    for down in down_stack:\n        x = down(x)\n        skips.append(x)\n    skips = reversed(skips[:-1])\n    for up, skip in zip(up_stack, skips):\n        x = up(x)\n        x = layers.Concatenate()([x, skip])\n    x = last(x)\n    return tf.keras.Model(inputs=inputs, outputs=x)\n\ndef Discriminator():\n    initializer = tf.random_normal_initializer(0., 0.02)\n    inp = layers.Input(shape=[256, 256, 1], name='input_image')\n    tar = layers.Input(shape=[256, 256, 3], name='target_image')\n    x = layers.concatenate([inp, tar])\n    down1 = downsample(64, 4, False)(x)\n    down2 = downsample(128, 4)(down1)\n    down3 = downsample(256, 4)(down2)\n    down4 = downsample(512, 4)(down3)\n    zero_pad1 = layers.ZeroPadding2D()(down4)\n    conv = layers.Conv2D(512, 4, strides=1, kernel_initializer=initializer, use_bias=False)(zero_pad1)\n    batchnorm1 = layers.BatchNormalization()(conv)\n    leaky_relu = layers.LeakyReLU()(batchnorm1)\n    zero_pad2 = layers.ZeroPadding2D()(leaky_relu)\n    last = layers.Conv2D(1, 4, strides=1, kernel_initializer=initializer)(zero_pad2)\n    return tf.keras.Model(inputs=[inp, tar], outputs=last)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-25T07:12:06.039360Z","iopub.execute_input":"2024-06-25T07:12:06.039718Z","iopub.status.idle":"2024-06-25T07:12:06.060019Z","shell.execute_reply.started":"2024-06-25T07:12:06.039688Z","shell.execute_reply":"2024-06-25T07:12:06.059020Z"},"trusted":true},"execution_count":88,"outputs":[]},{"cell_type":"code","source":"def generator_loss(disc_generated_output, gen_output, target):\n    gan_loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)(tf.ones_like(disc_generated_output), disc_generated_output)\n    l1_loss = tf.reduce_mean(tf.abs(target - gen_output))\n    total_gen_loss = gan_loss + (100 * l1_loss)\n    return total_gen_loss\n\ndef discriminator_loss(disc_real_output, disc_generated_output):\n    real_loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)(tf.ones_like(disc_real_output), disc_real_output)\n    generated_loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)(tf.zeros_like(disc_generated_output), disc_generated_output)\n    total_disc_loss = real_loss + generated_loss\n    return total_disc_loss\n","metadata":{"execution":{"iopub.status.busy":"2024-06-25T07:12:07.218012Z","iopub.execute_input":"2024-06-25T07:12:07.218356Z","iopub.status.idle":"2024-06-25T07:12:07.225278Z","shell.execute_reply.started":"2024-06-25T07:12:07.218331Z","shell.execute_reply":"2024-06-25T07:12:07.224318Z"},"trusted":true},"execution_count":89,"outputs":[]},{"cell_type":"code","source":"@tf.function\ndef train_step(input_image, target, epoch):\n    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n        gen_output = generator(input_image, training=True)\n        disc_real_output = discriminator([input_image, target], training=True)\n        disc_generated_output = discriminator([input_image, gen_output], training=True)\n        gen_loss = generator_loss(disc_generated_output, gen_output, target)\n        disc_loss = discriminator_loss(disc_real_output, disc_generated_output)\n    generator_gradients = gen_tape.gradient(gen_loss, generator.trainable_variables)\n    discriminator_gradients = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n    generator_optimizer.apply_gradients(zip(generator_gradients, generator.trainable_variables))\n    discriminator_optimizer.apply_gradients(zip(discriminator_gradients, discriminator.trainable_variables))\n    return gen_loss, disc_loss\n","metadata":{"execution":{"iopub.status.busy":"2024-06-25T07:12:08.387937Z","iopub.execute_input":"2024-06-25T07:12:08.388627Z","iopub.status.idle":"2024-06-25T07:12:08.396119Z","shell.execute_reply.started":"2024-06-25T07:12:08.388592Z","shell.execute_reply":"2024-06-25T07:12:08.395098Z"},"trusted":true},"execution_count":90,"outputs":[]},{"cell_type":"code","source":"from datasets import load_dataset\n\ndataset = load_dataset('ILSVRC/imagenet-1k', split=\"test\", streaming=True, trust_remote_code=True) # Using test dataset for training","metadata":{"execution":{"iopub.status.busy":"2024-06-25T07:12:09.962619Z","iopub.execute_input":"2024-06-25T07:12:09.963014Z","iopub.status.idle":"2024-06-25T07:12:11.870894Z","shell.execute_reply.started":"2024-06-25T07:12:09.962980Z","shell.execute_reply":"2024-06-25T07:12:11.870102Z"},"trusted":true},"execution_count":91,"outputs":[]},{"cell_type":"code","source":"# Preprocess image function\ndef preprocess_image(example):\n    image = np.array(example['image'])\n    if image.shape[-1] == 3:  # Check for RGB image\n        image = cv2.resize(image, (256, 256))\n        grayscale_image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n        grayscale_image = grayscale_image[..., np.newaxis]  # Add channel dimension\n        return grayscale_image, image\n    return None, None\n\n# Fit function with MLflow logging\ndef fit(dataset, epochs):\n    batch_size = 32\n    log_interval = 100\n    save_interval = 500\n\n    \n    # Start an MLflow run\n#     mlflow.start_run(experiment_id = experiment_id, run_name=f'Run{mlflow.search_runs(experiment_id).shape[0] + 1}')\n    mlflow.log_params({\n        \"batch_size\": batch_size,\n        \"epochs\": epochs,\n#         \"generator_lr\": g_lr,\n#         \"discriminator_lr\": d_lr,\n        \"beta\": beta,\n        \"log_interval\": log_interval,\n        \"save_interval\": save_interval\n    })\n    \n    for epoch in range(epochs):\n        batch_counter = 0\n        batch_input = []\n        batch_labels = []\n        for i, example in enumerate(dataset):\n            grayscale_image, image = preprocess_image(example)\n            if grayscale_image is not None:\n                batch_input.append(grayscale_image)\n                batch_labels.append(image)\n            if len(batch_input) == batch_size:\n                batch_input = tf.convert_to_tensor(np.array(batch_input, dtype=np.float32) / 255.0)\n                batch_labels = tf.convert_to_tensor(np.array(batch_labels, dtype=np.float32) / 127.5 - 1)\n                gen_loss, disc_loss = train_step(batch_input, batch_labels, epoch)\n                batch_input = []\n                batch_labels = []\n                batch_counter += 1\n\n                if batch_counter % log_interval == 0:\n                    # Log metrics to MLflow\n                    mlflow.log_metric('gen_loss', gen_loss.numpy(), step=batch_counter)\n                    mlflow.log_metric('disc_loss', disc_loss.numpy(), step=batch_counter)\n                    print(f'Batch {batch_counter} done')\n                    if batch_counter % save_interval == 0:\n                        generator.save(f'generator_weights_batch_{batch_counter:04d}.h5')\n                        discriminator.save(f'discriminator_weights_batch_{batch_counter:04d}.h5')\n                        print(\"Saved\")\n\n        # Log epoch-end models and metrics\n        mlflow.log_metric('gen_loss_epoch', gen_loss.numpy(), step=epoch)\n        mlflow.log_metric('disc_loss_epoch', disc_loss.numpy(), step=epoch)\n        generator.save(f'generator_weights_epoch_{epoch+1:04d}.h5')\n        discriminator.save(f'discriminator_weights_epoch_{epoch+1:04d}.h5')\n        print(f\"Saved epoch {epoch+1}\")\n\n        # Log model artifacts\n#         mltf.log_model(generator, f\"generator_epoch_{epoch+1}.keras\")\n#         mltf.log_model(discriminator, f\"discriminator_epoch_{epoch+1}.keras\")\n        \n\n    mlflow.end_run()\n","metadata":{"execution":{"iopub.status.busy":"2024-06-25T12:02:08.507592Z","iopub.execute_input":"2024-06-25T12:02:08.507997Z","iopub.status.idle":"2024-06-25T12:02:08.523765Z","shell.execute_reply.started":"2024-06-25T12:02:08.507963Z","shell.execute_reply":"2024-06-25T12:02:08.522843Z"},"trusted":true},"execution_count":111,"outputs":[]},{"cell_type":"code","source":"# generator = Generator()\n# discriminator = Discriminator()\n\ngenerator = tf.keras.models.load_model(\"/kaggle/working/generator_weights_batch_3000.h5\")\ndiscriminator = tf.keras.models.load_model(\"/kaggle/working/discriminator_weights_batch_3000.h5\")\n\ng_lr = 2e-4\nd_lr = 2e-3\nbeta = 0.5\nepochs = 5\n\n# Optimizers\ngenerator_optimizer = tf.keras.optimizers.Adam(g_lr, beta)\ndiscriminator_optimizer = tf.keras.optimizers.Adam(d_lr, beta)\n\n# Start training\nfit(dataset, epochs = epochs)\n\n# Save final weights\ngenerator.save('final_generator_weights.h5')\ndiscriminator.save('final_discriminator_weights.h5')\n","metadata":{"execution":{"iopub.status.busy":"2024-06-25T12:51:20.017150Z","iopub.execute_input":"2024-06-25T12:51:20.017551Z","iopub.status.idle":"2024-06-25T13:35:12.648192Z","shell.execute_reply.started":"2024-06-25T12:51:20.017518Z","shell.execute_reply":"2024-06-25T13:35:12.646375Z"},"trusted":true},"execution_count":113,"outputs":[{"name":"stdout","text":"Batch 100 done\nBatch 200 done\nBatch 300 done\nBatch 400 done\nBatch 500 done\nSaved\nBatch 600 done\nBatch 700 done\nBatch 800 done\nBatch 900 done\nBatch 1000 done\nSaved\nBatch 1100 done\nBatch 1200 done\nBatch 1300 done\nBatch 1400 done\nBatch 1500 done\nSaved\nBatch 1600 done\nBatch 1700 done\nBatch 1800 done\nBatch 1900 done\nBatch 2000 done\nSaved\nBatch 2100 done\nBatch 2200 done\nBatch 2300 done\nBatch 2400 done\nBatch 2500 done\nSaved\nBatch 2600 done\nBatch 2700 done\nBatch 2800 done\nBatch 2900 done\nBatch 3000 done\nSaved\nSaved epoch 1\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[113], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m discriminator_optimizer \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(d_lr, beta)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Start training\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Save final weights\u001b[39;00m\n\u001b[1;32m     20\u001b[0m generator\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinal_generator_weights.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n","Cell \u001b[0;32mIn[111], line 42\u001b[0m, in \u001b[0;36mfit\u001b[0;34m(dataset, epochs)\u001b[0m\n\u001b[1;32m     40\u001b[0m batch_input \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(np\u001b[38;5;241m.\u001b[39marray(batch_input, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255.0\u001b[39m)\n\u001b[1;32m     41\u001b[0m batch_labels \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(np\u001b[38;5;241m.\u001b[39marray(batch_labels, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m127.5\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 42\u001b[0m gen_loss, disc_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m batch_input \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     44\u001b[0m batch_labels \u001b[38;5;241m=\u001b[39m []\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n","File \u001b[0;32m/tmp/__autograph_generated_file5yq6db1e.py:18\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_step\u001b[0;34m(input_image, target, epoch)\u001b[0m\n\u001b[1;32m     16\u001b[0m generator_gradients \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(gen_tape)\u001b[38;5;241m.\u001b[39mgradient, (ag__\u001b[38;5;241m.\u001b[39mld(gen_loss), ag__\u001b[38;5;241m.\u001b[39mld(generator)\u001b[38;5;241m.\u001b[39mtrainable_variables), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     17\u001b[0m discriminator_gradients \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(disc_tape)\u001b[38;5;241m.\u001b[39mgradient, (ag__\u001b[38;5;241m.\u001b[39mld(disc_loss), ag__\u001b[38;5;241m.\u001b[39mld(discriminator)\u001b[38;5;241m.\u001b[39mtrainable_variables), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m---> 18\u001b[0m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerator_optimizer\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_gradients\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerator_gradients\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(discriminator_optimizer)\u001b[38;5;241m.\u001b[39mapply_gradients, (ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mzip\u001b[39m), (ag__\u001b[38;5;241m.\u001b[39mld(discriminator_gradients), ag__\u001b[38;5;241m.\u001b[39mld(discriminator)\u001b[38;5;241m.\u001b[39mtrainable_variables), \u001b[38;5;28;01mNone\u001b[39;00m, fscope),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/optimizers/base_optimizer.py:282\u001b[0m, in \u001b[0;36mBaseOptimizer.apply_gradients\u001b[0;34m(self, grads_and_vars)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_gradients\u001b[39m(\u001b[38;5;28mself\u001b[39m, grads_and_vars):\n\u001b[1;32m    281\u001b[0m     grads, trainable_variables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mgrads_and_vars)\n\u001b[0;32m--> 282\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;66;03m# Return iterations for compat with tf.keras.\u001b[39;00m\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterations\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/optimizers/base_optimizer.py:321\u001b[0m, in \u001b[0;36mBaseOptimizer.apply\u001b[0;34m(self, grads, trainable_variables)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilt:\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mname_scope(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, caller\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 321\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_variables_are_known(trainable_variables)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/optimizers/adam.py:97\u001b[0m, in \u001b[0;36mAdam.build\u001b[0;34m(self, var_list)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_velocities \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m var \u001b[38;5;129;01min\u001b[39;00m var_list:\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_momentums\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m---> 97\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_variable_from_reference\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreference_variable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmomentum\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     99\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m     )\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_velocities\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m    102\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_variable_from_reference(\n\u001b[1;32m    103\u001b[0m             reference_variable\u001b[38;5;241m=\u001b[39mvar, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvelocity\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    104\u001b[0m         )\n\u001b[1;32m    105\u001b[0m     )\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mamsgrad:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/backend/tensorflow/optimizer.py:36\u001b[0m, in \u001b[0;36mTFOptimizer.add_variable_from_reference\u001b[0;34m(self, reference_variable, name, initializer)\u001b[0m\n\u001b[1;32m     31\u001b[0m     colocate_var \u001b[38;5;241m=\u001b[39m reference_variable\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_distribution_strategy\u001b[38;5;241m.\u001b[39mextended\u001b[38;5;241m.\u001b[39mcolocate_vars_with(\n\u001b[1;32m     34\u001b[0m     colocate_var\n\u001b[1;32m     35\u001b[0m ):\n\u001b[0;32m---> 36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_variable_from_reference\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreference_variable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitializer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializer\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/optimizers/base_optimizer.py:218\u001b[0m, in \u001b[0;36mBaseOptimizer.add_variable_from_reference\u001b[0;34m(self, reference_variable, name, initializer)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    213\u001b[0m     name \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    214\u001b[0m         \u001b[38;5;28mstr\u001b[39m(reference_variable\u001b[38;5;241m.\u001b[39mname)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    215\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    216\u001b[0m         \u001b[38;5;241m+\u001b[39m name\n\u001b[1;32m    217\u001b[0m     )\n\u001b[0;32m--> 218\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_variable\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreference_variable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitializer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreference_variable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/optimizers/base_optimizer.py:192\u001b[0m, in \u001b[0;36mBaseOptimizer.add_variable\u001b[0;34m(self, shape, initializer, dtype, aggregation, name)\u001b[0m\n\u001b[1;32m    190\u001b[0m initializer \u001b[38;5;241m=\u001b[39m initializers\u001b[38;5;241m.\u001b[39mget(initializer)\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mname_scope(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, caller\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 192\u001b[0m     variable \u001b[38;5;241m=\u001b[39m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mVariable\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43minitializer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrainable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43maggregation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maggregation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_track_variable(variable)\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m variable\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/backend/common/variables.py:165\u001b[0m, in \u001b[0;36mKerasVariable.__init__\u001b[0;34m(self, initializer, shape, dtype, trainable, autocast, aggregation, name)\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    164\u001b[0m         value \u001b[38;5;241m=\u001b[39m initializer\n\u001b[0;32m--> 165\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ndim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shape)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/backend/tensorflow/core.py:31\u001b[0m, in \u001b[0;36mVariable._initialize\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_initialize\u001b[39m(\u001b[38;5;28mself\u001b[39m, value):\n\u001b[0;32m---> 31\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mVariable\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/tmp/ipykernel_34/3535119356.py\", line 11, in train_step  *\n        generator_optimizer.apply_gradients(zip(generator_gradients, generator.trainable_variables))\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/optimizers/base_optimizer.py\", line 282, in apply_gradients  **\n        self.apply(grads, trainable_variables)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/optimizers/base_optimizer.py\", line 321, in apply\n        self.build(trainable_variables)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/optimizers/adam.py\", line 97, in build\n        self.add_variable_from_reference(\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/backend/tensorflow/optimizer.py\", line 36, in add_variable_from_reference\n        return super().add_variable_from_reference(\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/optimizers/base_optimizer.py\", line 218, in add_variable_from_reference\n        return self.add_variable(\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/optimizers/base_optimizer.py\", line 192, in add_variable\n        variable = backend.Variable(\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/backend/common/variables.py\", line 165, in __init__\n        self._initialize(value)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/backend/tensorflow/core.py\", line 31, in _initialize\n        self._value = tf.Variable(\n\n    ValueError: tf.function only supports singleton tf.Variables created on the first call. Make sure the tf.Variable is only created once or created outside tf.function. See https://www.tensorflow.org/guide/function#creating_tfvariables for more information.\n"],"ename":"ValueError","evalue":"in user code:\n\n    File \"/tmp/ipykernel_34/3535119356.py\", line 11, in train_step  *\n        generator_optimizer.apply_gradients(zip(generator_gradients, generator.trainable_variables))\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/optimizers/base_optimizer.py\", line 282, in apply_gradients  **\n        self.apply(grads, trainable_variables)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/optimizers/base_optimizer.py\", line 321, in apply\n        self.build(trainable_variables)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/optimizers/adam.py\", line 97, in build\n        self.add_variable_from_reference(\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/backend/tensorflow/optimizer.py\", line 36, in add_variable_from_reference\n        return super().add_variable_from_reference(\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/optimizers/base_optimizer.py\", line 218, in add_variable_from_reference\n        return self.add_variable(\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/optimizers/base_optimizer.py\", line 192, in add_variable\n        variable = backend.Variable(\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/backend/common/variables.py\", line 165, in __init__\n        self._initialize(value)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/backend/tensorflow/core.py\", line 31, in _initialize\n        self._value = tf.Variable(\n\n    ValueError: tf.function only supports singleton tf.Variables created on the first call. Make sure the tf.Variable is only created once or created outside tf.function. See https://www.tensorflow.org/guide/function#creating_tfvariables for more information.\n","output_type":"error"}]},{"cell_type":"code","source":"mlflow.end_run()","metadata":{"execution":{"iopub.status.busy":"2024-06-25T09:24:14.236832Z","iopub.execute_input":"2024-06-25T09:24:14.237585Z","iopub.status.idle":"2024-06-25T09:24:14.404488Z","shell.execute_reply.started":"2024-06-25T09:24:14.237551Z","shell.execute_reply":"2024-06-25T09:24:14.403770Z"},"trusted":true},"execution_count":101,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nimport cv2\n\ndef preprocess_image_for_inference(image_path):\n    image = cv2.imread(image_path)\n    if image is None:\n        raise ValueError(\"Image not found or unable to read\")\n    if image.shape[-1] == 3:  # Check for RGB image\n        image = cv2.resize(image, (256, 256))\n        grayscale_image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n        grayscale_image = grayscale_image[..., np.newaxis]  # Add channel dimension\n        grayscale_image = tf.convert_to_tensor(np.array(grayscale_image, dtype=np.float32) / 255.0)\n        grayscale_image = tf.expand_dims(grayscale_image, axis=0)  # Add batch dimension\n        return grayscale_image\n    else:\n        raise ValueError(\"Image is not in RGB format\")\n\ndef postprocess_output_image(output_tensor):\n    output_image = output_tensor[0]  # Remove batch dimension\n    output_image = (output_image + 1) * 127.5  # Scale from [-1, 1] to [0, 255]\n    output_image = np.array(output_image, dtype=np.uint8)\n    return output_image\n\n# Load the trained generator model\ngenerator = tf.keras.models.load_model('models/generator_weights_batch_3000.h5')\n\n# Path to the input image\ninput_image_path = 'image.jpeg'\n\n# Preprocess the input image\npreprocessed_image = preprocess_image_for_inference(input_image_path)\n\n# Run the generator model to get the output\ngenerated_output = generator(preprocessed_image, training=False)\n\n# Post-process the output image\noutput_image = postprocess_output_image(generated_output)\n\n# Save or display the output image\noutput_image_path = 'path_to_your_output_image.jpg'\ncv2.imwrite(output_image_path, output_image)\n","metadata":{},"execution_count":null,"outputs":[]}]}